{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "g:\\python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "g:\\python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "g:\\python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "g:\\python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "g:\\python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "g:\\python\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "g:\\python\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "g:\\python\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "g:\\python\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "g:\\python\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "g:\\python\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import config\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from DataLoader import FeatureDictionary, DataParser\n",
    "\n",
    "from model import XdeepFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    dfTrain = pd.read_csv(config.TRAIN_FILE)\n",
    "    dfTest = pd.read_csv(config.TEST_FILE)\n",
    "\n",
    "    def preprocess(df):\n",
    "        cols = [c for c in df.columns if c not in [\"id\", \"target\"]]\n",
    "        df[\"missing_feat\"] = np.sum((df[cols] == -1).values, axis=1)\n",
    "        df[\"ps_car_13_x_ps_reg_03\"] = df[\"ps_car_13\"] * df[\"ps_reg_03\"]\n",
    "        return df\n",
    "\n",
    "    dfTrain = preprocess(dfTrain)\n",
    "    dfTest = preprocess(dfTest)\n",
    "\n",
    "    cols = [c for c in dfTrain.columns if c not in [\"id\", \"target\"]]\n",
    "    cols = [c for c in cols if (not c in config.IGNORE_COLS)]\n",
    "\n",
    "    X_train = dfTrain[cols].values\n",
    "    y_train = dfTrain[\"target\"].values\n",
    "    X_test = dfTest[cols].values\n",
    "    ids_test = dfTest[\"id\"].values\n",
    "\n",
    "    return dfTrain, dfTest, X_train, y_train, X_test, ids_test,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_data_over\n",
      "process_data_over\n"
     ]
    }
   ],
   "source": [
    "dfTrain, dfTest, X_train, y_train, X_test, ids_test = load_data()\n",
    "print('load_data_over')\n",
    "folds = list(StratifiedKFold(n_splits=config.NUM_SPLITS, shuffle=True,\n",
    "                             random_state=config.RANDOM_SEED).split(X_train, y_train))\n",
    "print('process_data_over')\n",
    "\n",
    "XdeepFM_params = {\n",
    "\n",
    "    \"embedding_size\": 8,\n",
    "    \"deep_layers\": [32, 32],\n",
    "    \"dropout_deep\": [0.5, 0.5, 0.5],\n",
    "    \"deep_layers_activation\": tf.nn.relu,\n",
    "    \"epoch\": 30,\n",
    "    \"batch_size\": 1024,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"optimizer_type\": \"adam\",\n",
    "    \"batch_norm\": 1,\n",
    "    \"batch_norm_decay\": 0.995,\n",
    "    \"l2_reg\": 0.01,\n",
    "    \"verbose\": True,\n",
    "    \"random_seed\": config.RANDOM_SEED,\n",
    "    \"cin_layer\":[124,124]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([   0,    1,    4, ..., 9996, 9997, 9999]),\n",
       "  array([   2,    3,    8, ..., 9991, 9994, 9998])),\n",
       " (array([   0,    1,    2, ..., 9996, 9997, 9998]),\n",
       "  array([   4,    5,    7, ..., 9992, 9993, 9999])),\n",
       " (array([   2,    3,    4, ..., 9994, 9998, 9999]),\n",
       "  array([   0,    1,    6, ..., 9995, 9996, 9997]))]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\myGitRepo\\RS-leanrn\\RS_tensorflow_local\\XDeepFM\\DataLoader.py:21: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  df = pd.concat([self.trainfile,self.testfile])\n"
     ]
    }
   ],
   "source": [
    "fd = FeatureDictionary(dfTrain,dfTest,numeric_cols=config.NUMERIC_COLS,\n",
    "                    ignore_cols=config.IGNORE_COLS,\n",
    "                        cate_cols = config.CATEGORICAL_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247\n",
      "{'ps_car_01_cat': {10: 0, 11: 1, 7: 2, 6: 3, 9: 4, 5: 5, 4: 6, 8: 7, 3: 8, 0: 9, 2: 10, 1: 11, -1: 12}, 'ps_car_02_cat': {1: 13, 0: 14}, 'ps_car_03_cat': {-1: 15, 0: 16, 1: 17}, 'ps_car_04_cat': {0: 18, 1: 19, 8: 20, 9: 21, 2: 22, 6: 23, 3: 24, 7: 25, 4: 26, 5: 27}, 'ps_car_05_cat': {1: 28, -1: 29, 0: 30}, 'ps_car_06_cat': {4: 31, 11: 32, 14: 33, 13: 34, 6: 35, 15: 36, 3: 37, 0: 38, 1: 39, 10: 40, 12: 41, 9: 42, 17: 43, 7: 44, 8: 45, 5: 46, 2: 47, 16: 48}, 'ps_car_07_cat': {1: 49, -1: 50, 0: 51}, 'ps_car_08_cat': {0: 52, 1: 53}, 'ps_car_09_cat': {0: 54, 2: 55, 3: 56, 1: 57, -1: 58, 4: 59}, 'ps_car_10_cat': {1: 60, 0: 61, 2: 62}, 'ps_car_11': {2: 63, 3: 64, 1: 65, 0: 66}, 'ps_car_11_cat': {12: 67, 19: 68, 60: 69, 104: 70, 82: 71, 99: 72, 30: 73, 68: 74, 20: 75, 36: 76, 101: 77, 103: 78, 41: 79, 59: 80, 43: 81, 64: 82, 29: 83, 95: 84, 24: 85, 5: 86, 28: 87, 87: 88, 66: 89, 10: 90, 26: 91, 54: 92, 32: 93, 38: 94, 83: 95, 89: 96, 49: 97, 93: 98, 1: 99, 22: 100, 85: 101, 78: 102, 31: 103, 34: 104, 7: 105, 8: 106, 3: 107, 46: 108, 27: 109, 25: 110, 61: 111, 16: 112, 69: 113, 40: 114, 76: 115, 39: 116, 88: 117, 42: 118, 75: 119, 91: 120, 23: 121, 2: 122, 71: 123, 90: 124, 80: 125, 44: 126, 92: 127, 72: 128, 96: 129, 86: 130, 62: 131, 33: 132, 67: 133, 73: 134, 77: 135, 18: 136, 21: 137, 74: 138, 37: 139, 48: 140, 70: 141, 13: 142, 15: 143, 102: 144, 53: 145, 65: 146, 100: 147, 51: 148, 79: 149, 52: 150, 63: 151, 94: 152, 6: 153, 57: 154, 35: 155, 98: 156, 56: 157, 97: 158, 55: 159, 84: 160, 50: 161, 4: 162, 58: 163, 9: 164, 17: 165, 11: 166, 45: 167, 14: 168, 81: 169, 47: 170}, 'ps_ind_01': {2: 171, 1: 172, 5: 173, 0: 174, 4: 175, 3: 176, 6: 177, 7: 178}, 'ps_ind_02_cat': {2: 179, 1: 180, 4: 181, 3: 182, -1: 183}, 'ps_ind_03': {5: 184, 7: 185, 9: 186, 2: 187, 0: 188, 4: 189, 3: 190, 1: 191, 11: 192, 6: 193, 8: 194, 10: 195}, 'ps_ind_04_cat': {1: 196, 0: 197, -1: 198}, 'ps_ind_05_cat': {0: 199, 1: 200, 4: 201, 3: 202, 6: 203, 5: 204, -1: 205, 2: 206}, 'ps_ind_06_bin': {0: 207, 1: 208}, 'ps_ind_07_bin': {1: 209, 0: 210}, 'ps_ind_08_bin': {0: 211, 1: 212}, 'ps_ind_09_bin': {0: 213, 1: 214}, 'ps_ind_10_bin': {0: 215, 1: 216}, 'ps_ind_11_bin': {0: 217, 1: 218}, 'ps_ind_12_bin': {0: 219, 1: 220}, 'ps_ind_13_bin': {0: 221, 1: 222}, 'ps_ind_14': {0: 223, 1: 224, 2: 225, 3: 226}, 'ps_ind_15': {11: 227, 3: 228, 12: 229, 8: 230, 9: 231, 6: 232, 13: 233, 4: 234, 10: 235, 5: 236, 7: 237, 2: 238, 0: 239, 1: 240}, 'ps_ind_16_bin': {0: 241, 1: 242}, 'ps_ind_17_bin': {1: 243, 0: 244}, 'ps_ind_18_bin': {0: 245, 1: 246}}\n"
     ]
    }
   ],
   "source": [
    "print(fd.feat_dim)\n",
    "print(fd.feat_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对特征进行转换，\n",
    "data_parser = DataParser(feat_dict=fd)\n",
    "cate_Xi_train, cate_Xv_train, numeric_Xv_train,y_train = data_parser.parse(df=dfTrain, has_label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 30, 10000, 10000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cate_Xi_train[0]),len(cate_Xv_train[0]),len(numeric_Xv_train),len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "    XdeepFM_params[\"cate_feature_size\"] = fd.feat_dim\n",
    "    XdeepFM_params[\"field_size\"] = len(cate_Xi_train[0])\n",
    "    XdeepFM_params['numeric_feature_size'] = len(config.NUMERIC_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6666 30\n",
      "6666 30\n",
      "6666 9\n",
      "10000\n",
      "WARNING:tensorflow:From H:\\myGitRepo\\RS-leanrn\\RS_tensorflow_local\\XDeepFM\\model.py:61: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:From H:\\myGitRepo\\RS-leanrn\\RS_tensorflow_local\\XDeepFM\\model.py:62: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From H:\\myGitRepo\\RS-leanrn\\RS_tensorflow_local\\XDeepFM\\model.py:193: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From g:\\python\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From H:\\myGitRepo\\RS-leanrn\\RS_tensorflow_local\\XDeepFM\\model.py:90: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "xo (?, ?)\n",
      "[<tf.Tensor 'transpose_3:0' shape=(?, 124, 8) dtype=float32>]\n",
      "(?, 1)\n",
      "(?, 156)\n",
      "WARNING:tensorflow:From H:\\myGitRepo\\RS-leanrn\\RS_tensorflow_local\\XDeepFM\\model.py:139: The name tf.losses.log_loss is deprecated. Please use tf.compat.v1.losses.log_loss instead.\n",
      "\n",
      "WARNING:tensorflow:From g:\\python\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From H:\\myGitRepo\\RS-leanrn\\RS_tensorflow_local\\XDeepFM\\model.py:155: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From H:\\myGitRepo\\RS-leanrn\\RS_tensorflow_local\\XDeepFM\\model.py:168: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From H:\\myGitRepo\\RS-leanrn\\RS_tensorflow_local\\XDeepFM\\model.py:169: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From H:\\myGitRepo\\RS-leanrn\\RS_tensorflow_local\\XDeepFM\\model.py:170: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "#params: 11436\n"
     ]
    }
   ],
   "source": [
    "_get = lambda x, l: [x[i] for i in l]\n",
    "\n",
    "for i, (train_idx, valid_idx) in enumerate(folds):\n",
    "    cate_Xi_train_, cate_Xv_train_, numeric_Xv_train_,y_train_ = _get(cate_Xi_train, train_idx), _get(cate_Xv_train, train_idx),_get(numeric_Xv_train, train_idx), _get(y_train, train_idx)\n",
    "    cate_Xi_valid_, cate_Xv_valid_, numeric_Xv_valid_,y_valid_ = _get(cate_Xi_train, valid_idx), _get(cate_Xv_train, valid_idx),_get(numeric_Xv_train, valid_idx), _get(y_train, valid_idx)\n",
    "    print(len(cate_Xi_train_),len(cate_Xi_train_[0])) \n",
    "    print(len(cate_Xv_train_),len(cate_Xv_train_[0]))    \n",
    "    print(len(numeric_Xv_train_),len(numeric_Xv_train_[0]))\n",
    "    print(len(y_train))\n",
    "\n",
    "        \n",
    "    \n",
    "    Xdeepfm = XdeepFM(**XdeepFM_params)\n",
    "    break\n",
    "    Xdeepfm.fit(cate_Xi_train_, cate_Xv_train_, numeric_Xv_train_,y_train_, cate_Xi_valid_, cate_Xv_valid_, numeric_Xv_valid_,y_valid_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XdeepFM(batch_norm=1, batch_norm_decay=0.995, batch_size=1024,\n",
       "        cate_feature_size=247, cin_layer=[124, 124], deep_layers=[32, 32],\n",
       "        deep_layers_activation=<function relu at 0x0000027AC451B1E0>,\n",
       "        dropout_deep=None, embedding_size=8, epoch=30,\n",
       "        eval_metric=<function roc_auc_score at 0x0000027ACB015268>,\n",
       "        field_size=30, greater_is_better=True, l2_reg=0.01, learning_rate=0.001,\n",
       "        loss_type='logloss', numeric_feature_size=9, optimizer_type='adam',\n",
       "        random_seed=2017, verbose=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xdeepfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
